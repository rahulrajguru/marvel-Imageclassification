# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xEoHEdCoXvrROz8ijKr-99lJqlr8i43N
"""

import os
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator


_url='https://www.kaggle.com/hchen13/marvel-heroes/download'
filename = tf.keras.utils.get_file('archive.zip', origin=_url, extract=True)
character=['black widow','captain america','doctor strange','hulk','iron man','loki','spider-man','thanos',]


base_directory =os.path.join(os.path.dirname(filename), 'marvel')
train_directory = os.path.join(base_directory, 'train')
validation_directory = os.path.join(base_directory, 'valid')



train_black_widow_directory = os.path.join(train_directory, 'black widow')  # directory with our training cat pictures
train_captian_america_directory = os.path.join(train_directory, 'captain america')  # directory with our training dog pictures
train_doctor_strange_directory=os.path.join(train_directory,'doctar strange')
train_hulk_directory=os.path.join(train_directory,'hulk')
train_iron_man_directory=os.path.join(train_directory,'iron man')
train_loki_directory=os.path.join(train_directory,'loki')
train_spiderman_directory=os.path.join(train_directory,'spider-man')
train_thanos_directory=os.path.join(train_directory,'thanos')

validation_black_widow_directory = os.path.join(validation_directory, 'black widow')
validation_captian_america_directory = os.path.join(validation_directory, 'captain america')  # directory with our training dog pictures
validation_doctor_strange_directory=os.path.join(validation_directory,'doctar strange')
validation_hulk_directory=os.path.join(validation_directory,'hulk')
validation_iron_man_directory=os.path.join(validation_directory,'iron man')
validation_loki_directory=os.path.join(validation_directory,'loki')
validation_spiderman_directory=os.path.join(validation_directory,'spider-man')
validation_thanos_directory=os.path.join(validation_directory,'thanos')



num_black_widow_train = len(os.listdir(train_black_widow_directory))
num_captian_america_train = len(os.listdir(train_captian_america_directory))
num_doctor_strange_train = len(os.listdir(train_doctor_strange_directory))
num_hulk_train = len(os.listdir(train_hulk_directory))
num_iron_man_train = len(os.listdir(train_iron_man_directory))
num_loki_train = len(os.listdir(train_loki_directory))
num_spiderman_train = len(os.listdir(train_spiderman_directory))
num_thanos_train = len(os.listdir(train_thanos_directory))


num_black_widow_val = len(os.listdir(validation_black_widow_directory))
num_captian_america_val = len(os.listdir(validation_captian_america_directory))
num_doctor_strange_val = len(os.listdir(validation_doctor_strange_directory))
num_hulk_val = len(os.listdir(validation_hulk_directory))
num_iron_man_val = len(os.listdir(validation_iron_man_directory))
num_loki_strange_val = len(os.listdir(validation_loki_directory))
num_spiderman_val = len(os.listdir(validation_spiderman_directory))
num_thanos_val = len(os.listdir(validation_thanos_directory))


total_train =num_black_widow_val+num_captian_america_val+num_doctor_strange_val+num_hulk_val +num_iron_man_val+num_loki_strange_val +num_spiderman_val+num_thanos_val
total_val = num_black_widow_val+num_captian_america_val+num_doctor_strange_val+num_hulk_val +num_iron_man_val+num_loki_strange_val +num_spiderman_val+num_thanos_val


print("Total training images:", total_train)
print("Total validation images:", total_val)




BATCH_SIZE = 150
IMG_SHAPE  = 150 


image_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)

train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,
                                               directory=train_directory,
                                               shuffle=True,
                                               target_size=(IMG_SHAPE,IMG_SHAPE))

image_gen = ImageDataGenerator(rescale=1./255, rotation_range=45)

train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,
                                               directory=train_directory,
                                               shuffle=True,
                                               target_size=(IMG_SHAPE, IMG_SHAPE))

image_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.5)

train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,
                                               directory=train_directory,
                                               shuffle=True,
                                               target_size=(IMG_SHAPE, IMG_SHAPE))


image_gen_val = ImageDataGenerator(rescale=1./255)
#rescaling only validaion images

val_data_gen = image_gen_val.flow_from_directory(batch_size=BATCH_SIZE,
                                                 directory=validation_directory,
                                                 target_size=(IMG_SHAPE, IMG_SHAPE),
                                                 class_mode='binary')


model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(2)
])



model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

epochs=100
history = model.fit_generator(
    train_data_gen,
    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),
    epochs=epochs,
    validation_data=val_data_gen,
    validation_steps=int(np.ceil(total_val / float(BATCH_SIZE)))
)